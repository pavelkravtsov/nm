{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import logging\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from random import random\n",
    "from pandas.core.frame import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Имена файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = \"data/text.txt\"\n",
    "pairs_with_gr_file = \"data/pairs_with_grammar.tsv\"\n",
    "relations_pairs_file = \"data/relations_pairs.tsv\"\n",
    "train_file = \"data/train.csv\"\n",
    "test_file = \"data/test.csv\"\n",
    "disperse_file = \"data/disperse_data.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка логгера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='preparation_results.log',\n",
    "                    format='[%(asctime)s] [%(levelname)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "lg = logging.getLogger(\"L\")\n",
    "lg.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "ch.setFormatter(formatter)\n",
    "lg.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка стеммера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 22:50:54,851 [INFO] Loading mystem\n",
      "2016-10-30 22:50:54,851 [INFO] Loading mystem\n",
      "2016-10-30 22:50:54,857 [INFO] Loaded mystem\n",
      "2016-10-30 22:50:54,857 [INFO] Loaded mystem\n"
     ]
    }
   ],
   "source": [
    "lg.info(\"Loading mystem\")\n",
    "m = Mystem()\n",
    "lg.info(\"Loaded mystem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_gr(gr):\n",
    "    options = re.search('\\(([^\\)]*)\\)', gr, re.IGNORECASE)\n",
    "\n",
    "    if options:\n",
    "        title = options.group(1)\n",
    "        for stuff in title.split('|'):\n",
    "            yield gr.replace(\"(\" + title + \")\", stuff)\n",
    "    else:\n",
    "        yield gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запись пар с их грамматической информацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем множество кортежей типа  \n",
    "(грамматическое описание, начальная форма, слово)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 22:50:58,414 [INFO] file opened\n",
      "2016-10-30 22:50:58,414 [INFO] file opened\n"
     ]
    }
   ],
   "source": [
    "lines = set([])\n",
    "\n",
    "with open(text_file, \"rt\") as input_file:\n",
    "    lg.info(\"file opened\")\n",
    "\n",
    "    for line in input_file:\n",
    "        \n",
    "        for w in m.analyze(line):\n",
    "            if 'analysis' in w:\n",
    "                for item in w['analysis']:\n",
    "                    for gramm_info in parse_gr(item['gr']):\n",
    "                        lines.add(\"\\t\".join(\n",
    "                            [gramm_info, item['lex'], w['text'].lower()]) + \"\\n\")\n",
    "                        # lines.add(\"\\t\".join(\n",
    "                        #     [gramm_info, item['lex'], w['text'].lower()]).encode(\"utf-8\") + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем их в файл pairs_with_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(pairs_with_gr_file, \"wt\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запись данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 22:56:07,484 [INFO] Pairs acquired\n",
      "2016-10-30 22:56:07,484 [INFO] Pairs acquired\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "\n",
    "for line in open(pairs_with_gr_file, \"rt\"):\n",
    "    if line.strip():\n",
    "        desc, normal, form = line.strip().split(\"\\t\")\n",
    "        if desc not in dict:\n",
    "            dict[desc] = []\n",
    "        dict[desc].append((normal, form))\n",
    "\n",
    "lg.info(\"Pairs acquired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И создаем декартово произведение пар (слово, нач. форма)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 22:57:31,722 [INFO] Relations pairs acquired\n",
      "2016-10-30 22:57:31,722 [INFO] Relations pairs acquired\n"
     ]
    }
   ],
   "source": [
    "writer = open(relations_pairs_file, \"w+\")\n",
    "\n",
    "for desc in dict:\n",
    "    for p0 in dict[desc]:\n",
    "        for p1 in dict[desc]:\n",
    "            if not p0 == p1:\n",
    "                writer.write(\"\\t\".join([p0[0], p0[1], p1[0], p1[1]]) + \"\\n\")\n",
    "\n",
    "writer.close()\n",
    "lg.info(\"Relations pairs acquired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прорежаем данные, если нужно (уменьшаем размер в factor раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 23:43:20,097 [INFO] Use Disperse data\n"
     ]
    }
   ],
   "source": [
    "factor = 1000\n",
    "\n",
    "if factor != 1:\n",
    "    with open(relations_pairs_file, \"rt\") as input_:\n",
    "        with open(disperse_file, \"wt\") as output:\n",
    "            for line in input_:\n",
    "                if random() < 1.0 / factor:\n",
    "                    output.write(line)\n",
    "            lg.info(\"Use Disperse data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим данные на данные для обучения и для тестирования (было в функции prepare_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 23:44:05,907 [INFO] Data acquired\n"
     ]
    }
   ],
   "source": [
    "splitting = 0.9\n",
    "\n",
    "all_data_list = pd.read_csv(relations_pairs_file if factor == 1 else disperse_file, \n",
    "                            header=None, encoding=\"utf-8\", sep=\"\\t\")\n",
    "all_data_list.dropna()\n",
    "\n",
    "# shuffle(all_data_list)\n",
    "\n",
    "splitting = int(math.floor(splitting * len(all_data_list)))\n",
    "train_ds = DataFrame(all_data_list[:splitting])\n",
    "test_ds = DataFrame(all_data_list[splitting:])\n",
    "\n",
    "train_ds.to_csv(train_file, encoding=\"utf-8\", index=False, header=False, sep=\",\", quotechar='\"')\n",
    "test_ds.to_csv(test_file, encoding=\"utf-8\", index=False, header=False, sep=\",\", quotechar='\"')\n",
    "lg.info(\"Data acquired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
